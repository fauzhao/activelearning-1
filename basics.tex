% !TEX root = ./active_learning.tex

\section*{General introduction} % (fold)
\label{sec:general_introduction}
Notation: \\
Data $\data$. New data $\data^*$. Parameters $\params$. Input $\inp$. Output $\outp$. Model $\model$. \\
\note{We might not mention the $\model$ explicitly in all the probabilities}.

We are interested in the posterior probability of the model paramters given the data
\begin{align}\label{eq:posterior}
	\prob{\params | \data, \model} = \frac{\prob{\data | \params, \model} \prior{\params, \model}}{\prob{\data, \model}}
\end{align}
The goal is to have little uncertainty in the posterior. 

The \emph{predictive distribution} is the probability $\prob{\data^* | \data, \model}$ of observing a new data point $\data^*$ given the old data $\data$ and a model $\model$.
\begin{align*}
	\prob{\data^* | \data, \model}
	&= \int \ud \params
		\prob{\data^*, \params | \data, \model} \\
	&= \int \ud \params
		\prob{\data^* | \data, \model, \params}
		\prob{\params | \data, \model} \\
	&= \int \ud \params
		\prob{\data^* | \model, \params}
		\prob{\params | \data, \model} \,,
\end{align*}
where in the last step we used $\prob{\data^* | \data, \model, \params} = \prob{\data^* | \model, \params}$, because the new data should depend only on the model and the parameters and not on the collected data. That is, we assume that the model captures all the structure in the data. This assumption is typical for Bayesian inference.

We want to maximize the expected information gain of the input $\inp$:
\begin{align}
	\utility(\inp)
	= H[p(\params | \data)]
	- \expect{\outp | \inp, \data} H[\prob{\params | \data, \inp, \outp}] \,,
\end{align}
which corresponds to minimizing the second term. This is called posterior entropy minimization.
We can get an alternative formulation by noting that
\begin{align}
	\utility(\inp)
	&= I[\params, \outp | \data, \inp] \\
	&= H[\prob{\outp | \inp, \data}]
	- \expect{\params | \data} H[\prob{\outp | \inp, \params}] \,,
\end{align}
where $I$ is the mutual information, which is symmetric in its arguments. Writing it this way allows for a different interpretation of $\utility(\inp)$
Now $H[\prob{\outp | \inp, \data}]$ should be large, which makes sense, because we should choose an input $\inp$ for which we don't know yet what the output $\outp$ will be. Furthermore $\expect{\params | \data} H[\prob{\inp | \outp, \params}]$ should be small, because we don't want to choose an input $\inp$ for which the output $\outp$ is very uncertain.
\note{Copied from Houlsby thesis:}
In other words, we seek the input $\inp$ for which the parameters under the posterior make confident predictions (term 2), but these predictions are highly diverse. That is, the parameters disagree about the output $\outp$, hence this formulation is named Bayesian Active Learning by Disagreement (BALD).
% subsection general_introduction (end)