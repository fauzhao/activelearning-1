% !TEX root = ./active_learning.tex

\section{Approximations} % (fold)
\label{sec:approximations}
We need to determine $K(x)$ for all $x$ values that we consider as worthwhile new stimuli. This can be many values and doing the involved integrals over posteriors is costly.
There are several ways to deal with this problem.

\subsection{Restricting the tested stimuli} % (fold)
\label{sub:restricting_the_tested_stimuli}
We need to discretize the $x$ anyways. We choose values.

\subsection{Approximating the posterior} % (fold)
 \label{sub:approximating_the_posterior}
We often determine the mean of a function over the posterior distribution. This is computationally expensive, in particular for large parameter spaces.
If we take samples of the posterior and approximate the integrals by smaller sums over the samples, we can save computation time. To get good samples from the posterior distribution we use the Metropolis-Hastings algorithm as an implementation of Markov Chain Monte Carlo integration.
As a proposal distribution $Q(x;x')$ we choose a multi variate normal distribution which determines the random walk that samples from the posterior.
 % subsection approximating_the_posterior (end) 

% subsection restricting_the_tested_stimuli (end)
% section approximations (end)